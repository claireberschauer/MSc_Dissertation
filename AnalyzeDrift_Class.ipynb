{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c34467a0-42e6-43ac-b566-d44529b20572",
   "metadata": {},
   "source": [
    "# Making a Drift Model Analysis Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d96d2ce-d8c1-49d6-9642-a7ff7fc8247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Analyze Drift Module\n",
    "\n",
    "This module contains a function to set up a Pandas data frame of Calibration\n",
    "data in the UDD ROOT format. It also has the AnalyzeDrift class, which defines \n",
    "a function to set up the drift_df data frame with drift time, drift radius, and \n",
    "cell type data. The class also contains a dictionary that contains all of the \n",
    "parameters needed to run Betsy's drift model and lists to define cell types and \n",
    "tag dead cells based on location with the tracker.\n",
    "\n",
    "Developed by Claire Berschauer for the SuperNEMO collaboration.\n",
    "Last edited: 05 September 2023\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import time as time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import uproot\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "634d6663-7522-4ba9-87ab-19e224a187f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_name, num_events=1000, all_events=False, verbose=False, \n",
    "\t\t\t\t print_time=True, branch='SimData;1', name='events.csv', \n",
    "\t\t\t\t index=False):\n",
    "\n",
    "    \"\"\" This function takes UDD ROOT format data (.root) and converts it to a \n",
    "    pandas data frame style .csv file.\n",
    "\n",
    "    :param file_name: Raw (commissioning) data, must be a UDD ROOT file.\n",
    "    :type file_name: str\n",
    "\n",
    "    :param num_events: Integer that indicates how many events you would like to \n",
    "    process. The default 1000 events takes about 30 minutes to run. Default is \n",
    "    1000 events.\n",
    "    :type num_events: int, optional\n",
    "\n",
    "    :param all_events: Option to process all events. WARNING: this function \n",
    "    takes a long time to run. If you choose all_events=True, the num_events \n",
    "    parameter will become obsolete. Default is False.\n",
    "    :type all_events: bool, optional\n",
    "\n",
    "    :param verbose: Indicates whether you would like the function to print \"n \n",
    "    of N complete\" after each event has been processed. This will also print \n",
    "    the time it takes for the function to run. Default is False.\n",
    "    :type verbose: bool, optional\n",
    "\n",
    "    :param print_time: To print the run time without printing a message after \n",
    "    each event iteration like the verbose kwarg does. Default is True. \n",
    "    :type print_time: bool, optional\n",
    "\n",
    "    :param branch: Defines the branch within the ROOT file to access. Default \n",
    "    is 'SimData;1'.\n",
    "    :type branch: str, optional\n",
    "\n",
    "    :param name: Determines what the resulting csv file will be called, default \n",
    "    is 'events.csv'. Default is 'events.csv'.\n",
    "    :type name: str, optional\n",
    "\n",
    "    :param index: Default of False does not include the index as a column in \n",
    "    the csv file. Default is False.\n",
    "    :type index: bool, optional\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    data = uproot.open(file_name)\n",
    "    id_branch = data[branch]['digitracker.id'].array(library='np')\n",
    "\n",
    "    if all_events is True:\n",
    "        n_events = len(id_branch)\n",
    "    else:\n",
    "        n_events = num_events\n",
    "\n",
    "    # initializing lists to be added as columns in the final data frame\n",
    "    event_nums = []\n",
    "    ids = []\n",
    "    sides = []\n",
    "    layers = []\n",
    "    columns = []\n",
    "    R0s = []\n",
    "    calo_times = []\n",
    "    rc_times = []\n",
    "\n",
    "    # loop to add all the datapoints into entries in the lists -- converts the \n",
    "    # root 'branch' format to a single list for each variable (so each hit's \n",
    "    # data is stored in a single row in the data frame)\n",
    "    for n in np.arange(n_events):\n",
    "        # indicates how many hits occur in the given event\n",
    "        id_list = np.array(id_branch[n], dtype='int')\n",
    "        num_hits = len(id_list)\n",
    "        \n",
    "        # calling information from the data file -- one array per variable per \n",
    "        # event and appending data to respective lists\n",
    "        try: \n",
    "            ev_R0s = data['SimData;1']['digitracker.anodetimestampR0'].array(\n",
    "            \t\t library='np')[n]  # R0 timestamps from anode \n",
    "            # [clock ticks], tail end of drift time\n",
    "            R0s.extend([x for [x] in ev_R0s])  # this format since ev_R0s is of \n",
    "            # the form [[#], [#], ...], so need to get rid of extra brackets\n",
    "            \n",
    "        except:\n",
    "            R0s.extend([np.nan] * num_hits)  # if an error occurs while \n",
    "            # extracting R0 data, which sometimes happens, this adds num_hits \n",
    "            # nan values to the R0s list to prevent mismatched list lengths\n",
    "        \n",
    "        try:\n",
    "            calo_times.extend([data['SimData;1']['digicalo.timestamp'].array( \n",
    "            library='np')[n][0]] * num_hits)  # using the first calorimeter \n",
    "            # timestamp arbitrarily as the trigger time. Note: the calorimeter \n",
    "            # clock runs twice as fast as the tracker clock.\n",
    "            rc_times.extend([data['SimData;1']['digicalo.rising_cell'].array( \n",
    "            library='np')[n][0]] * num_hits)  # needed for pulse start time\n",
    "\n",
    "        except:\n",
    "            calo_times.extend([np.nan] * num_hits)  # once again adding nan \n",
    "            # values if an exception occurs\n",
    "            rc_times.extend([np.nan] * num_hits)\n",
    "        \n",
    "        \n",
    "        ev_sides = data['SimData;1']['digitracker.side'].array( \n",
    "        \t\t   library='np')[n]  # French side = 1, Italian = 0 (Since \n",
    "                   # France is #1!)\n",
    "        ev_layers = data['SimData;1']['digitracker.layer'].array(\n",
    "        \t\t\t\t library='np')[n]  # Layer 0 near source foil, layer 8 \n",
    "                         # by calo wall\n",
    "        ev_columns = data['SimData;1']['digitracker.column'].array( \n",
    "        \t\t\t library='np')[n]  # Column 0 on mountain side, col 112 on \n",
    "                     # tunnel side\n",
    "        ev_ids = data['SimData;1']['digitracker.id'].array(library='np')[n] \n",
    "        # line above is for Event IDs\n",
    "\n",
    "        # use .extend() to append lists rather than individual items\n",
    "        event_nums.extend([n] * num_hits)  # all hits in each iteration should \n",
    "        # have the same event ID, so add num_hits IDs to the list\n",
    "        sides.extend(ev_sides)\n",
    "        layers.extend(ev_layers)\n",
    "        columns.extend(ev_columns)\n",
    "        ids.extend(ev_ids)\n",
    "        \n",
    "        # Prints a message after every iteration; nice for low numbers of events\n",
    "        if verbose is True:\n",
    "            print(n + 1, 'of', n_events, 'complete')\n",
    "    \n",
    "    # Creates a dictionary of the data lists with corresponding names to be \n",
    "    # used as column names in the data frame\n",
    "    data={'Event':event_nums, 'ID':ids, 'Side':sides, 'Column':columns, \n",
    "    \t  'Layer':layers, 'R0':R0s, 'Calo_time':calo_times, \n",
    "    \t  'Rising_cell_time':rc_times\n",
    "    \t  }\n",
    "    \n",
    "    # Makes a data frame of the data and saves it as a .csv file in the same \n",
    "    # folder as the program running this function\n",
    "    event_df = pd.DataFrame(data)\n",
    "    event_df.to_csv(name, index=index)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    # Prints runtime\n",
    "    if verbose is True:\n",
    "        print('Runtime:', (end - start)/60, 'minutes')\n",
    "    elif print_time is True:\n",
    "        print('Runtime:', (end - start)/60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a890b55-a0e6-40e2-bf7a-4eb5d8dfda0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyzeDrift():\n",
    "    \"\"\" The AnalyzeDrift class aims to streamline the process of data \n",
    "\tpreparation for drift radius calculation. It automatically finds drift \n",
    "\ttimes based on timestamp data, identifies cell type based on location, and \n",
    "\tcalculates drift radius, compiling all relevant information in the drift_df \n",
    "\tattribute. \n",
    "    \n",
    "    :param file_name: Name of the input data frame. Ideally this data frame \n",
    "    will be in the form produced by the process_data function, since column \n",
    "    names are assumed to be 'Event', 'ID', 'Side', 'Column', 'Layer', 'R0', \n",
    "    'Calo_time', and 'Rising_cell_time'. Data needs to be a .csv file input. \n",
    "    :type file_name: str\n",
    "\n",
    "    :param index: Allows the user to input a new index column if desired. \n",
    "    Default 42 indicates that the pandas.read_csv() function shouldn't specify \n",
    "    and index column.\n",
    "    :type index: int, optional\n",
    "\n",
    "    :param pressure: Tells the functions what pressure to use when selecting \n",
    "    drift model parameters. The default, 880, is closest to the actual \n",
    "    demonstrator module tracking chamber gas pressure. Parameters have been \n",
    "    calculated for pressure values of 850, 880, and 910. \n",
    "    :type pressure: int, optional\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_name, index=42, pressure=880):\n",
    "        \n",
    "        # Dictionaries!\n",
    "        \n",
    "        # ab_vals contains information on the parameters a and b that \n",
    "        # characterize the drift moodel for radius calculation and the value tx \n",
    "        # that gives the threshold for a particle being in the 'inner' or \n",
    "        # 'outer' region of the cell. a, b, and tx are pressure-dependent, \n",
    "        # which is why each entry has three tuples of three values.\n",
    "        \n",
    "        # 'region_name' : [(a_850, b_850, tx_850), (a_880, b_880, tx_880), ... \n",
    "        # ... (a_910, b_910, tx_910)]\n",
    "        \n",
    "        self.ab_vals = {'center_in': [(8.28, -0.9, 2.95), (8.53, -0.9, 2.97), \n",
    "        \t\t\t\t\t\t\t  (8.77, -0.9, 3.06)],\n",
    "                        'center_out': [(3.86, -1.99, 2.95), (4.19, -1.93, 2.97),\n",
    "                        \t\t\t   (4.55, -1.9, 3.06)],\n",
    "                        'edge_in': [(8.05, -0.9, 3.73), (8.35, -0.92, 4.15), \n",
    "                        \t\t\t(8.56, -0.9, 4.12)],\n",
    "                        'edge_out': [(3.34, -2.04, 3.73), (3.39, -2.07, 4.15), \n",
    "                        \t\t\t (4.03, -1.91, 4.12)],\n",
    "                        'corner_in': [(7.66, -0.87, 3.34), (7.92, -0.87, 3.45), \n",
    "                        \t\t\t  (8.16, -0.87, 3.59)],\n",
    "                        'corner_out': [(5.18, -1.4, 3.34), (4.94, -1.48, 3.45), \n",
    "                        \t\t\t   (5.25, -1.45, 3.59)]\n",
    "                       }\n",
    "        \n",
    "        # Cell Identification!\n",
    "        # entry = (side, column, layer)\n",
    "        \n",
    "        self.dead_cells = [(0, 1, 1), (0, 2, 1), (0, 3, 0), (0, 4, 3), \n",
    "        \t\t\t\t   (0, 9, 0), (0, 11, 0), (0, 21, 0), (0, 56, 3), \n",
    "                           (0, 56, 4), (0, 56, 5), (0, 57, 0), (0, 63, 8), \n",
    "                           (0, 70, 0), (0, 74, 4), (0, 77, 8), (0, 84, 0), \n",
    "                           (0, 86, 8), (0, 87, 0), (0, 89, 1), (0, 101, 3), \n",
    "                           (1, 32, 0), (1, 47, 8), (1, 56, 4), (1, 56, 5),\n",
    "                           (1, 73, 2), (1, 79, 6), (1, 80, 2), (1, 84, 5), \n",
    "                           (1, 91, 2), (1, 99, 8), (1, 100, 4), (1, 107, 8),\n",
    "                           (1, 110, 0)]\n",
    "        \n",
    "        self.corner_cells = [(0, 0, 0), (0, 112, 0), (0, 0, 8), (0, 112, 8), \n",
    "        \t\t\t\t\t (1, 0, 0), (1, 112, 0), (1, 0, 8), (1, 112, 8)]\n",
    "        \n",
    "        adj_cells = []  # finding calls adjacent to dead cells\n",
    "\n",
    "        for tpl in self.dead_cells:\n",
    "            adj_1 = (tpl[0], tpl[1] + 1, tpl[2])  # one column up\n",
    "            adj_2 = (tpl[0], tpl[1] - 1, tpl[2])  # one column down\n",
    "            adj_3 = (tpl[0], tpl[1], tpl[2] + 1)  # one layer up\n",
    "            adj_4 = (tpl[0], tpl[1], tpl[2] - 1)  # one layer down\n",
    "            \n",
    "            adj_cells.append(adj_1)\n",
    "            adj_cells.append(adj_2)\n",
    "            adj_cells.append(adj_3)\n",
    "            adj_cells.append(adj_4)\n",
    "            \n",
    "\n",
    "        adj_cells_in_det = [a for a in adj_cells if a[1] in range(113) and \n",
    "                            a[2] in range(9)]  # ensuring within tracker area\n",
    "            \n",
    "        self.adjacent_cells = list(set(adj_cells_in_det))\n",
    "        \n",
    "        ec = [(0, 0, l1) for l1 in np.arange(9)] \n",
    "        ec.extend([(0, c1, 0) for c1 in np.arange(113)])\n",
    "        ec.extend([(0, 112, l2) for l2 in np.arange(9)]) \n",
    "        ec.extend([(0, c2, 8) for c2 in np.arange(113)])\n",
    "        ec.extend([(1, 0, l3) for l3 in np.arange(9)]) \n",
    "        ec.extend([(1, c3, 0) for c3 in np.arange(113)])\n",
    "        ec.extend([(1, 112, l4) for l4 in np.arange(9)]) \n",
    "        ec.extend([(1, c4, 8) for c4 in np.arange(113)])\n",
    "        ec.extend(self.adjacent_cells)  # to consider dead-cell adjacent cells \n",
    "        # as edge cells in drift radius calculations\n",
    "        \n",
    "        self.edge_cells = [c for c in ec if c not in self.corner_cells]  # this \n",
    "        # line removes overlaps with corner cells\n",
    "        \n",
    "        cc = [(s, c, l) for s in np.arange(1) for c in np.arange(113) \n",
    "        \t  for l in np.arange(9)]\n",
    "        cc = [c for c in cc if c not in self.corner_cells]  # removes overlaps \n",
    "        # with corner cells\n",
    "        \n",
    "        self.center_cells = [c for c in cc if c not in self.edge_cells]  # this \n",
    "        # line removes overlaps with edge cells\n",
    "        \n",
    "        # Reading the data file\n",
    "        if index == 42:\n",
    "            df = pd.read_csv(file_name)\n",
    "        else:\n",
    "            df = pd.read_csv(file_name, index=index)\n",
    "        \n",
    "        # Initializing other attributes of the class\n",
    "        self.original_df = df\n",
    "        self.pressure = pressure\n",
    "        self.drift_times = None\n",
    "        self.drift_radii = None\n",
    "        self.params = None\n",
    "        \n",
    "        self.calc_drift_time()\n",
    "        self.drift_df = pd.concat([self.original_df, self.drift_times], axis=1)\n",
    "        self.find_region()\n",
    "        self.drift_df = pd.concat([self.drift_df, self.cell_types], axis=1)\n",
    "        self.calc_radius()\n",
    "        self.drift_df = pd.concat([self.drift_df, self.drift_radii], axis = 1)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # Data Preparation Functions                                              #\n",
    "    ###########################################################################\n",
    "    \n",
    "    def calc_drift_time(self):\n",
    "        \"\"\" Calculates the drift time using timestamp data from the input data \n",
    "        file.\n",
    "        \"\"\"\n",
    "        \n",
    "        post_trigger = 200  # setting configured to 200 ns; this is a fixed \n",
    "        # parameter to tune the position of the pusle in the record window\n",
    "        sampling_period = 0.39062000 # [ns]\n",
    "        pulse_start_time = (self.original_df['Rising_cell_time'] * \n",
    "        \t\t\t\t   sampling_period / 256)  # rising cell time is the \n",
    "        # start time measured by the FEB firmwave with constant fraction \n",
    "        # discriminatior method; it is the time when the pulse amplitude \n",
    "        # reached 25% of the maximum amplitude\n",
    "        converted_calo = self.original_df['Calo_time']*6.25  # calorimeter \n",
    "        # timestamps in ns\n",
    "        converted_anode = self.original_df['R0']*12.5  # first anode timestamp \n",
    "        # in ns\n",
    "        \n",
    "        drift_times = (converted_anode - (converted_calo - 400 +  \n",
    "        \t\t\t   post_trigger + pulse_start_time)) * 10**(-3)  # calculat-\n",
    "        # -ion and conversion to us\n",
    "        \n",
    "        self.drift_times = pd.Series(data=drift_times, name='Drift_time') \n",
    "        \n",
    "    def define_io(self, t_drift, region):\n",
    "        \"\"\" Defines whether the particle passes through the inner or outer \n",
    "        section of the drift cell.\n",
    "\n",
    "        :param t_drift: The measured drift time, should be a single value.\n",
    "        :type t_drift: float\n",
    "\n",
    "        :param region: The cell type. This entry can be 'center', 'edge', or \n",
    "        'corner'.\n",
    "        :type region: str\n",
    "        \"\"\"\n",
    "        \n",
    "        if t_drift > self.ab_vals[region+'_in'][1][2]:\n",
    "            inner = False  # indicates outer\n",
    "        else:\n",
    "            inner = True  # indicates inner\n",
    "        \n",
    "        return inner\n",
    "    \n",
    "    def find_region(self):\n",
    "        \"\"\" Identifies whether the drift cell is edge, corner, or center based \n",
    "        on the lists in __init__. \n",
    "        \"\"\"\n",
    "        \n",
    "        # initializing the list\n",
    "        cell_types = []\n",
    "        \n",
    "        # looping over all the rows\n",
    "        for n in np.arange(len(self.drift_df.index)):\n",
    "            cell = (self.drift_df['Side'][n], self.drift_df['Column'][n], \n",
    "            \t\tself.drift_df['Layer'][n])  # gives location coordinates \n",
    "                    # of the cell\n",
    "            \n",
    "            # consults the lists to determine what type of cell it is\n",
    "            if cell in self.edge_cells:\n",
    "                region = 'edge'\n",
    "            elif cell in self.corner_cells:\n",
    "                region = 'corner'\n",
    "            else:\n",
    "                region = 'center'\n",
    "            \n",
    "            # calls define_io to determine location within the cell\n",
    "            inner = self.define_io(self.drift_df['Drift_time'][n], region)  \n",
    "\n",
    "            # adds the in/out label so the result is compatible with the \n",
    "            # parameter dictionary keys\n",
    "            if inner is True:\n",
    "                cell_types.append(region + '_in')\n",
    "            else: \n",
    "                cell_types.append(region + '_out')\n",
    "            \n",
    "        self.cell_types = pd.Series(data=cell_types, name='Cell_type')\n",
    "\n",
    "    def find_params(self, cell_type):\n",
    "        \"\"\" Consults the ab_vals dictionary to determine a and b parameter \n",
    "        values.\n",
    "        \n",
    "        :param cell_type: Defines the cell type and location within the cell, \n",
    "        e.g. 'center_in'.\n",
    "        :type cell_type: str\n",
    "        \"\"\"\n",
    "\n",
    "        pressure = self.pressure\n",
    "        \n",
    "        if pressure == 850:\n",
    "            n = 0\n",
    "        elif pressure == 880:\n",
    "            n = 1\n",
    "        elif pressure == 910:\n",
    "            n = 2 \n",
    "        \n",
    "        # finds the parameters stored in the dictionary based on region and \n",
    "        # pressure\n",
    "        params = self.ab_vals[cell_type][n]\n",
    "        a = params[0]\n",
    "        b = params[1]\n",
    "        tx = params[2]\n",
    "\n",
    "        return params\n",
    "\n",
    "    def calc_radius(self):\n",
    "        \"\"\" Calculates the radius of the particle based on drift time and cell \n",
    "        type.\n",
    "        \"\"\"\n",
    "        \n",
    "        # initializing the list\n",
    "        radii = []\n",
    "        \n",
    "        # loops over all rows\n",
    "        for n in np.arange(len(self.drift_df.index)):\n",
    "            params = self.find_params(self.cell_types[n])  # calls find_params \n",
    "            # to define a and b\n",
    "            a = params[0]\n",
    "            b = params[1]\n",
    "\n",
    "            rad = (self.drift_times[n] / a)**(1 / (1 - b))  # calculates the \n",
    "            # radius\n",
    "            radii.append(rad)\n",
    "        \n",
    "        self.drift_radii = pd.Series(data=radii, name='Drift_radius')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
